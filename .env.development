# ===========================================
# DEVELOPMENT Environment
# ===========================================

# Server
SERVER_HOST=0.0.0.0
SERVER_PORT=4040
SERVER_READ_TIMEOUT=600s
SERVER_WRITE_TIMEOUT=600s

# Database (Docker local)
POSTGRES_HOST=localhost
POSTGRES_PORT=55432
POSTGRES_USER=texttosql
POSTGRES_PASSWORD=texttosql123
POSTGRES_DB=texttosql
POSTGRES_SSL_MODE=disable
POSTGRES_MAX_CONNS=20

# Redis (Docker local)
REDIS_HOST=localhost
REDIS_PORT=56379
REDIS_PASSWORD=
REDIS_DB=0

# Vault (Docker local)
VAULT_ADDR=http://localhost:58200
VAULT_TOKEN=devtoken

# Auth
JWT_SECRET=your_very_long_and_secure_jwt_secret_key_here_minimum_32_chars
ACCESS_TOKEN_TTL=24h
REFRESH_TOKEN_TTL=168h

# LLM Providers
LLM_DEFAULT_PROVIDER=ollama

# LLM API Keys (set only the ones you want to use)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
DEEPSEEK_API_KEY=
GEMINI_API_KEY=AIzaSyBk3s5I-Fz8yRnCXmW8kVWXejR4YXcVjhE

# OpenAI
OPENAI_MODEL=gpt-4-turbo

# Anthropic
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Gemini
GEMINI_MODEL=gemini-1.5-flash

# DeepSeek
DEEPSEEK_MODEL=deepseek-chat

# Ollama (local)
OLLAMA_HOST=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3

# Timeouts
SERVER_IDLE_TIMEOUT=120s
SERVER_SHUTDOWN_TIMEOUT=30s
SERVER_MIDDLEWARE_TIMEOUT=600s
SERVER_LLM_TIMEOUT=600s
