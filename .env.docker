# ============================================
# Docker Environment Configuration
# Copy this file to .env and customize values
# ============================================

# === Backend Server ===
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
SERVER_READ_TIMEOUT=60s
SERVER_WRITE_TIMEOUT=60s
SERVER_IDLE_TIMEOUT=120s
SERVER_SHUTDOWN_TIMEOUT=30s
SERVER_MIDDLEWARE_TIMEOUT=300s
SERVER_LLM_TIMEOUT=300s

# === PostgreSQL Database ===
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=texttosql
POSTGRES_PASSWORD=change_this_secure_password
POSTGRES_DB=texttosql
POSTGRES_SSL_MODE=disable
POSTGRES_MAX_CONNS=20

# === Redis Cache ===
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# === Vault (Optional) ===
VAULT_ADDR=http://vault:8200
VAULT_TOKEN=devtoken

# === Authentication ===
JWT_SECRET=your_very_long_and_secure_jwt_secret_key_here_minimum_32_chars
ACCESS_TOKEN_TTL=24h
REFRESH_TOKEN_TTL=168h

# === LLM Configuration ===
LLM_DEFAULT_PROVIDER=ollama

# Ollama (default - local LLM, no key needed)
# Use host.docker.internal to access host machine's Ollama
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_DEFAULT_MODEL=llama3

# OpenAI (optional)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4-turbo

# Anthropic (optional)
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Gemini (optional)
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash

# DeepSeek (optional)
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=deepseek-chat

# === Frontend ===
VITE_API_BASE_URL=/api/v1
